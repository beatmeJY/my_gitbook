---
description: 레디스 자료 구조 활용사례
---

# Chapter 4

## 실시간 리더보드 (sorted set)

### 리더보드란?

> 경쟁자들의 순위와 현재 점수를 보여주는 순위표를 의미한다.
>
> 주로 게임에서 스코어로 정렬돼 상위 경쟁자의 순위를 보여주는 용도로 쓰이지만, 게임 외의 서비스에서도 여러 데이터들을 게임화하여 리더보드로 나타내는 방식을 자주 사용하고 있다.

#### 절대적 리더보드란

> 모든 유저를 정렬시켜 상위권의 목록만을 표시한다.

#### 상대적 리더보드란

> 사용자마다 다른 데이터를 보여주며 사용자의 스코어를 기반으로 다른 사용자와 비교해 순위를 결정하는 형태의 리더보드이다.



### 실시간 랭킹리더보드 예시

```sql
ZADD daily-score:240617 28 player:286
ZADD daily-score:240617 400 player:234
ZADD daily-score:240617 45 player:101

ZREVRANGE daily-score:240617 0 2 withscores
"player:234"
"400"
"player:101"
"45"
"player:286"
"28"
```

* 레디스의 sorted set은 데이터가 저장될 때부터 정렬되어 들어가기 때문에,
* 유저의 score를 가중치로 설정한다면 스코어 순으로 유저가 정렬되어 매번 데이터를 정렬할 필요가 없다.
* 일별 리더보드를 도입하기 위해서 `daily-score:<날짜>`를 이용해 sorted set 키를 만들고 사용자의 스코어를 가중치로 사용해서 데이터를 만들 수 있다.
* `ZREVRANGE`를 사용해서 높은 스코어부터 검색하여 오늘의 상위 스코어 3명을 출력 할 수 있다.

```sql
ZADD daily-score:240617 200 player:286
ZINCRBY daily-score:240617 172 player:286
```

* 만약 플레이어의 스코어를 갱신해야 한다면 위와 같은 커맨드로 쉽게 갱신 할 수 있다.
  * **ZADD**: 같은 데이터는 중복으로 저장 되지 않으므로 새로운 스코어로 갱신된다.
  * **ZINCRBY**: `INCREBY` 커맨드와 비슷하게 동작하여 스코어를 입력한 만큼 증가시킬 수도 있다.

```sql
ZUINONSTORE weekly-score:2406-3 7 
daily-score:240617 daily-score:240618 daily-score:240619 daily-score:240620 
daily-score:240621 daily-score:240622 daily-score:240623
```

* **ZUINONSTORE**: 지정한 키에 연결된 각 아이템의 스코어를 합산하는 커맨드이다.
  * 만약 주말에 2배 점수 이벤트를 한다면 마지막에 `WEIGHTS` 옵션으로 가중치를 둘 수 있다.
  * 위 코드의 맨 마지막 구문에 이와 같이 추가. `weight 1 1 1 1 1 2 2`



## 최근 검색 기록 (sorted set)

> 사용자별 가장 최근에 검색한 검색 기록 5개만을 가져온다 가정하자.

```sql
ZADD search-keyword:123 20240616103212 육개장사발면
```

* sorted set에 score를 날짜로 넣어 정렬을 하는 방법을 사용할 수 있다.
* sorted set은 중복을 허용하지 않으므로 동일한 검색 결과도 존재 하지 않는다.
* 동일한 검색 결과가 발생했다면 가장 최근에 검색한 데이터로 변경이 될 뿐이다.

<figure><img src="../../.gitbook/assets/image (1) (1) (1) (1).png" alt="" width="563"><figcaption></figcaption></figure>

* 만일 검색기록이 5개 이상이면 가장 오래전 검색 결과를 삭제해야 하는데,
* 이는 음수 인덱스를 사용하면 -6 (가장 오래된 데이터) 부터 안전하게 삭제 할 수 있다.
* 이는 만약 데이터가 5개 밖에 없더라도 -6 인덱스를 삭제하는 명령이므로 아무런 문제가 없다.



## 태그 기능 (set)

> 블로그와 같은 게시물을 작성할 때 태그를 추가하고자 할 경우를 가정한다.

```
SADD post:47:tags IT REDIS SessionStore
SADD post:22:tags IT JAVA
SADD post:53:tags IT REDIS
```

* **SADD**: 각 게시물이 사용하는 태그를 set을 이용해 저장한다.
* 이렇게 게시물을 키로 저장하면 해당 포스트에 사용된 태그들의 정보를 확인 할 수 있다.

```sql
SADD tag:REDIS:posts 47
SADD tag:IT:posts 47
SADD tag:IT:posts 22 53

SMEMBERS tag:IT:posts
> "22"
> "47"
> "53"
```

* **SADD**: 각 태그에 포함되는 게시물을 저장한다.
* 이렇게 태그를 키로 저장하면 해당 태그를 가지고 있는 포스트 정보들을 모아 볼 수 있다.

```sql
SINTER tag:IT:posts tag:REDIS:posts
> "47"
> "53"
```

* **SINTER**: 특정 tag의 교집합을 확인할 수 있다.
* 이렇게 특정 태그들을 포함하고 있는 게시글을 찾아낼 때에도 유용하게 사용할 수 있다.
* 이를 RDB에서 조회한다면 `group by - having`을 사용하는 등 DB자체에 부하를 발생 시킬 수 있다.



## 랜덤 데이터 추출

***

> 랜덤으로 이벤트에 응모한 유저를 랜덤으로 추출하는 로직을 가정해 보자.

### 랜덤 추출시 RDB의 단점

* 이러한 랜덤 데이터 추출을 RDB에서 할 경우 ORDER BY RAND() 함수를 많이 사용하게 된다.
* 하지만 이는 조건 절에 맞는 모든 행을 읽은 뒤, 임시 테이블에 넣어 정렬한 다음 랜덤으로 추출한다.
* 이와 같은 데이터가 1만 건 이상일 경우 성능이 나빠지게 되고 굉장히 큰 부하가 가는 방법일 수 있다.

### 레디스에서 랜덤 추출은?

* 레디스의 RANDOMKEY를 사용하면 O(1)의 시간 복잡도를 이용해 랜덤한 데이터를 추출할 수 있다.
* `hash`는 `HRANDFIELD,` `set`은 `SRANDMEMBER`, `sorted set`은 `ZRANDMEMBER`로 할 수 있다.

```sql
HRANDFIELD user:hash
> "Id:4615"

HRANDFIELD user:hash 1 WITHVALUES
> "Id:4615"
> "MangGu"
```

* **HRANDFIELD**: 지정한 hash 내에서 임의로 선택된 하나의 아이템을 추출할 수 있다.
* **WITHVALUES**: 필드에 연결된 값도 함께 반환한다.

```sql
HRANDFIELD user:hash 2
> "Id:4615"
> "Id:134"

HRANDFIELD user:hash -2
> "Id:134"
> "Id:134"
```

* `COUNT` 옵션을 줄 경우 `양수이면 중복되지 않는 랜덤값`을 꺼내고, `음수이면 중복해서 반환 될 수도` 있다.



## 다양한 카운팅 방법

***

### 좋아요 처리하기

* 트래픽이 굉장히 많은 사이트라면 1초에 몇만 개 이상의 좋아요가 생길 수도 있다.
* 이는 좋아요 개수를 증가시키는데 RDB로써는 상당한 부하를 겪게 된다.
* 또한 한 사용자는 같은 댓글에 한번씩만 좋아요를 할 수 있으므로 어떤 유저가 좋아요를 눌렀는지 까지도 파악해야 한다.
* Redis에서는 이러한 것은 `set`으로 생성하여 저장하면 중복 없이 데이터를 저장할 수 있다.

```sql
SADD comment-like:12554 967
SADD comment-like:125 42
SADD comment-like:12554 42

SCARD comment-like:12554
> 2
```

* **SCARD**: 해당 커맨드를 통해 해당 글을 몇 명이 좋아요를 눌렀는지 확인할 수 있다.

### 읽지 않은 메시지 수 카운팅하기

* 채널의 ID를 아이템의 키로 활용해 숫자 형태의 메시지 카운트를 관리하는 방법을 고려할 수 있다.

```sql
HINCRBY user:234 Channel:4234 1
HINCRBY user:123 Channel:133 -1
```

* **HINCREBY**: 사용자가 새로운 메시지를 받은 경우 숫자를 1 증가 시킬 수 있다.
* 반대로 사용자가 확인하였거나 보낸 전송자가 삭제한 경우 음수를 통해 감소 시킬 수도 있다.

### DAU 구하기 (Daily Active User)

> DAU란 하루동안 서비스에 방문한 사용자의 수를 의미한다.

* 하루 1,000만 명 이상의 유저가 방문하는 큰 서비스라면 `set`에 유저ID를 저장하는 방법은 하나의 키에 너무 많은 아이템이 저장 될 수 있으며 성능의 저하로 이어질 수 있다.
  * 보통 키 하나당 최대 저장 아이템은 최대 200\~300만 개까지로 조정을 권장한다.

```sql
SETBIT uv:20240617 14 1
SETBIT uv:20240617 7 1
SETBIT uv:20240617 3 1
SETBIT uv:20240618 14 1
SETBIT uv:20240618 3 1

BITCOUNT uv:20240617
> 3
```

* **SETBIT**: 20240617에 접속한 사용자 id가 14, 7, 3 각 3명의 비트 부호 자리를 1로 바꾸어준다.
* **BITCOUNT**: 20240617에 접속한 모든 사용자의 수를 구한다.

```
BITOP AND event:202406 uv:20240617 uv:20240618
> 2

GET event:202406
> "\x10\x02"
```

* **BITOP**: `AND`, `OR`, `XOR`, `NOT` 연산을 할 수 있다
* `AND` 커맨드를 통해 2일 모두 접속한 사용자를 event:202406에 저장하였다.
* `GET event:202406`으로 두 사용자 비트 위치를 받았다. (16진수)
  * 00010000 00000010 (\x10 \x02)

### hyperloglog를 이용한 어플리케이션 미터링

> 클라우드 환경에서 미터링은 중요한 과제이다.
>
> 사용자가 서비스를 사용한 만큼 지불해야하므로 사용자 별로 사용량을 정확하게 측정해야 한다.

* 예를 들어 한 명의 사용자가 1초에 100개씩 로그가 쌓이는 서버를 사용하면 한 달에 2억 6천개 정도의 로그가 쌓일 수 있다.
* 이런 서버가 여러대가 존재한다면 몇 만명의 각 사용자의 총 로그의 개수를 측정하는 로직 자체가 큰 부하가 될 것이다.
* 따라서 아래의 조건을 만족한다면 `hyperloglog`를 사용하는 것을 고려해볼 가치가 있다.
  * 집합 내의 유일한 데이터의 개수를 카운팅한다.
  * `1% 미만의 오차는 허용` 가능하다.
  * 카운팅할 때 사용한 정확한 데이터를 다시 확인하지 않아도 된다.
* 일반적인 방법으로 중복을 피하기 위해 저장된 데이터를 모두 기억하므로 많은 메모리를 사용하지만,
* `hyperloglog`는 최소한의 메모리만을 사용해 중복되지 않는 데이터의 개수를 계산할 수 있다.
* `hyperloglog`는 `set`과 비슷하지만 저장되는 용량이 12KB로 고정되기 떄문에 공간을 굉장히 효율적으로 사용할 수 있다는 장점을 가진다.

```
PFADD 202406:user:123 3271
PFADD 202406:user:123 4683
PFADD 202406:user:123 3271

PFCOUNT 202406:user:123
> 2

PFMERGE 2024:user:123 202405:user:123 202406:user:123
PFCOUNT 2024:user:123
> 8
```

* **PFADD**: 로그 식별자를 저장한다.
* **PFCOUNT**: 해당 중복되지 않은 데이터 개수를 확인할 수 있다.
* **PFMERGE**: 여러 개의 hyperloglog를 합칠 수 있어 분기나 연도별 합산 데이터를 간편하게 계산할 수도 있다.

## Geospatial Index를 이용한 위치 기반 어플리케이션 개발

***

> 위치 데이터는 주로 경도 위도 좌표 쌍으로 표현되며 이러한 공간 데이터를 처리하는 것은 개발 과정에서 쉽지 않은 과제 중 하나이다.

사용자 위치가 실시간으로 변할 때 위치 데이터 저장소는 다음과 같은 기능을 제공해야 한다.

* 사용자의 현재 위치 파악.
* 사용자의 이동에 따른 실시간 변동 위치 업데이트.
* 사용자의 위치를 기준으로 근처의 장소 검색.

하지만 위와 같은 기능들은 간단해 보이지만 사용자의 증가에 따라 1초마다 업데이트한다고 가정하면 데이터는 몇 십배로 증가할 것이다.

### 레디스에서의 위치 데이터

* 레디스는 geo 자료 구조를 통해 공간 정보 데이터를 처리할 수 있다.
* 공간 데이터를 활용한 연산 역시 메모리에서 빠르게 계산될 수 있어 효율적으로 처리할 수 있다.
* 특히 레디스 내에서 실제 데이터 가공 및 처리까지 이루어질 수 있어 네트워크 트래픽을 감소시키고 어플리케이션의 코드 복잡성도 감소 시킬 수 있어 빠른 응답 속도를 보장한다.

```
GEOADD user 50.071462321313 14.146456464566 142
GEOADD user 50.071462322238 14.146456556434 142 
```

* **GEOADD**: 현재 사용자의 위치 정보를 저장할 수 있다.
* 사용자 위치 정보를 실시간 업데이트 하더라도 동일한 커맨드를 사용할 수 있어 덮어 씌워진다.

```
GEOADD restaurant 50.07146286003341 14.414496454175485 ukalendu
GEOSEARCH restaurant fromlonlat 50.0682458281510288 14.4181846658358366 byradius 1 km
> "ukalendu"
```

* 프라하의 맛집을 `restaurant`라는 키에 저장한다.
* `FROMLONLAT` 옵션을 이용해 직접 경도와 위도를 지정해 해당 근처 1km 내의 레스토랑을 찾는다.
* `BYRADIUS`를 사용하면 반지름 1km 인 원의 영역, `BYBOX`를 사용하면 직사각형 영역을 검색한다.

